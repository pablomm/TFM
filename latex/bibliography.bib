@INPROCEEDINGS{kitty,
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
  year={2012},
  volume={},
  number={},
  pages={3354-3361},
  doi={10.1109/CVPR.2012.6248074}}

@article{pomerleau:alvinn,
author = {Pomerleau, Dean A.},
title = {ALVINN: An Autonomous Land Vehicle in a Neural Network},
year = {1989},
isbn = {1558600159},
journal = {Advances in Neural Information Processing Systems 1},
pages = {305–313},
numpages = {9}
}

@inproceedings{liu2022pseudo,
    title={Pseudo Numerical Methods for Diffusion Models on Manifolds},
    author={Luping Liu and Yi Ren and Zhijie Lin and Zhou Zhao},
    booktitle={2022 International Conference on Learning Representations (ICLR)},
    year={2022},
    url={https://openreview.net/forum?id=PlKWVd2yBkY}
}

@article{SAM,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  volume={abs/2304.02643},
  journal={ArXiv},
  year={2023}
}

@article{Zhang2021RethinkingSS,
  title={Rethinking Semantic Segmentation Evaluation for Explainability and Model Selection},
  author={Yuxiang Zhang and Sachin Mehta and Anat Caspi},
  journal={ArXiv},
  year={2021},
  volume={abs/2101.08418}
}

@article{Cho2021WeightedIO,
  title={Weighted Intersection over Union (wIoU): A New Evaluation Metric for Image Segmentation},
  author={Yeong-Jun Cho},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.09858}
}

@INPROCEEDINGS{metrics1,
  author={Fernandez-Moral, Eduardo and Martins, Renato and Wolf, Denis and Rives, Patrick},
  booktitle={2018 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={A New Metric for Evaluating Semantic Segmentation: Leveraging Global and Contour Accuracy}, 
  year={2018},
  volume={},
  number={},
  pages={1051-1056},
  doi={10.1109/IVS.2018.8500497}}

@inproceedings{
  song2021scorebased,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={2021 International Conference on Learning Representations (ICLR)},
  year={2021},
  url={https://openreview.net/forum?id=PxTIG12RRHS}
}


 @misc{lilianweng, title={What are diffusion models?}, url={https://lilianweng.github.io/}, journal={Lil'Log}, howpublished={https://lilianweng.github.io/posts/2021-07-11-diffusion-models/}, author={Weng, Lilian}, year={2021}, 
 note={Accessed: 2023-03-16}
 } 

 @inproceedings{
schuhmann2022laionb,
title={{LAION}-5B: An open large-scale dataset for training next generation image-text models},
author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade W Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa R Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=M3Y74vmsMcY}
}

@article{zhang2023adding,
  title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
  author={Lvmin Zhang and Maneesh Agrawala},
  year={2023},
  volume={abs/2302.05543},
  journal={arXiv},
  primaryClass={cs.CV}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={2021 International Conference on Machine Learning (ICLR)},
  year={2021}
}

@InProceedings{pmlr-v37-sohl-dickstein15,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {2015 International Conference on Machine Learning (ICLR)},
  pages = 	 {2256--2265},
  year = 	 {2015},
  volume = 	 {37},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
}


@ARTICLE{SemanticSegmentationSurvey,
  author={Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Image Segmentation Using Deep Learning: A Survey}, 
  year={2022},
  volume={44},
  number={7},
  pages={3523-3542},
  doi={10.1109/TPAMI.2021.3059968}}
  
@article{Grigorescu2019ASO,
  title={A survey of deep learning techniques for autonomous driving},
  author={Sorin Mihai Grigorescu and Bogdan Trasnea and Tiberiu T. Cocias and Gigel Macesanu},
  journal={Journal of Field Robotics},
  year={2019},
  volume={37},
  pages={362 - 386}
}


@article{BDD100K,
  title={BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning},
  author={Fisher Yu and Haofeng Chen and Xin Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and Vashisht Madhavan and Trevor Darrell},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  pages={2633-2642}
}
@article{Geyer2020A2D2AA,
  title={A2D2: Audi Autonomous Driving Dataset},
  author={Jakob Geyer and Yohannes Kassahun and Mentar Mahmudi and Xavier Ricou and Rupesh Durgesh and Andrew S. Chung and Lorenz Hauswald and Viet Hoang Pham and Maximilian M{\"u}hlegg and Sebastian Dorn and Tiffany Fernandez and Martin J{\"a}nicke and Sudesh Ganapati Mirashi and Chiragkumar Savani and M. Sturm and Oleksandr Vorobiov and Martin Oelker and Sebastian Garreis and Peter Schuberth},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.06320}
}

@InProceedings{gtav,
author="Richter, Stephan R. and Vineet, Vibhav and Roth, Stefan and Koltun, Vladlen",
title="Playing for Data: Ground Truth from Computer Games",
booktitle="2016 European Conference Computer Vision (ECCV)",
year="2016",
pages="102--118",
isbn="978-3-319-46475-6"
}


@INPROCEEDINGS{SYNTHIA,
  author={Ros, German and Sellart, Laura and Materzynska, Joanna and Vazquez, David and Lopez, Antonio M.},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes}, 
  year={2016},
  volume={},
  number={},
  pages={3234-3243},
  doi={10.1109/CVPR.2016.352}}
  
@inproceedings{CarlaSimulator,
  added-at = {2020-08-28T00:00:00.000+0200},
  author = {Dosovitskiy, Alexey and Ros, Germán and Codevilla, Felipe and López, Antonio M. and Koltun, Vladlen},
  biburl = {https://www.bibsonomy.org/bibtex/2add7ad04435010632f3642dafd5099a8/dblp},
  booktitle = {CoRL},
  ee = {http://proceedings.mlr.press/v78/dosovitskiy17a.html},
  interhash = {b021cdd665a32c19861c10033fbe547c},
  intrahash = {add7ad04435010632f3642dafd5099a8},
  keywords = {dblp},
  pages = {1-16},
  series = {Proceedings of Machine Learning Research},
  timestamp = {2020-08-29T11:39:48.000+0200},
  title = {CARLA: An Open Urban Driving Simulator.},
  url = {http://dblp.uni-trier.de/db/conf/corl/corl2017.html#DosovitskiyRCLK17},
  volume = 78,
  year = 2017
}

@inproceedings{Varma_2019,
	doi = {10.1109/wacv.2019.00190},
	url = {https://doi.org/10.1109\%2Fwacv.2019.00190},
	year = 2019,
	month = {jan},
	publisher = {{IEEE}},
	author = {Girish Varma and Anbumani Subramanian and Anoop Namboodiri and Manmohan Chandraker and C.V. Jawahar},
	title = {{IDD}: A Dataset for Exploring Problems of Autonomous Navigation in Unconstrained Environments},
	booktitle = {2019 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})}
}

@article{wang2019apolloscape,
  author={Huang, Xinyu and Wang, Peng and Cheng, Xinjing and Zhou, Dingfu and Geng, Qichuan and Yang, Ruigang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={The ApolloScape Open Dataset for Autonomous Driving and Its Application}, 
  year={2020},
  volume={42},
  number={10},
  pages={2702-2719},
  doi={10.1109/TPAMI.2019.2926463},
}

@InProceedings{wildash2,
    author    = {Zendel, Oliver and Sch\"orghuber, Matthias and Rainer, Bernhard and Murschitz, Markus and Beleznai, Csaba},
    title     = {Unifying Panoptic Segmentation for Autonomous Driving},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {21351-21360}
}

@InProceedings{mapilliary,
author = {Neuhold, Gerhard and Ollmann, Tobias and Rota Bulo, Samuel and Kontschieder, Peter},
title = {The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@INPROCEEDINGS{FCN,
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Fully convolutional networks for semantic segmentation}, 
  year={2015},
  volume={},
  number={},
  pages={3431-3440},
  doi={10.1109/CVPR.2015.7298965}}

@inproceedings{DeeplabV3,
author = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
title = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation},
year = {2018},
isbn = {978-3-030-01233-5},
url = {https://doi.org/10.1007/978-3-030-01234-2_49},
doi = {10.1007/978-3-030-01234-2_49},
booktitle = {2018 European Conference Computer Vision (ECCV)},
pages = {833–851},
numpages = {19},
keywords = {Depthwise separable convolution, Semantic image segmentation, Encoder-decoder, Spatial pyramid pooling},
}

@InProceedings{UNET,
author="Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="2015 Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
year="2015",
pages="234--241",
}








@article{surveySemanticSegmentationArchitectures,
author = {Irem Ulku and Erdem Akagündüz},
title = {A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D Images},
journal = {Applied Artificial Intelligence},
volume = {36},
number = {1},
pages = {2032924},
year  = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/08839514.2022.2032924},
URL = {https://doi.org/10.1080/08839514.2022.2032924},
eprint = { https://doi.org/10.1080/08839514.2022.2032924}
}

@INPROCEEDINGS{Zhang2017,
  author={Zhang, Yang and David, Philip and Gong, Boqing},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes}, 
  year={2017},
  volume={},
  number={},
  pages={2039-2049},
  doi={10.1109/ICCV.2017.223}}

@article{Tung2019SimilarityPreservingKD,
  title={Similarity-Preserving Knowledge Distillation},
  author={Frederick Tung and Greg Mori},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  pages={1365-1374}
}

@inproceedings{Tsai_adaptseg_2018,
  author = {Y.-H. Tsai and W.-C. Hung and S. Schulter and K. Sohn and M.-H. Yang and M. Chandraker},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title = {Learning to Adapt Structured Output Space for Semantic Segmentation},
  year = {2018}
}

@article{Sun2019HighResolutionRF,
  title={High-Resolution Representations for Labeling Pixels and Regions},
  author={Ke Sun and Yang Zhao and Borui Jiang and Tianheng Cheng and Bin Xiao and Dong Liu and Yadong Mu and Xinggang Wang and Wenyu Liu and Jingdong Wang},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.04514}
}

@article{HRNET,
  title={Deep High-Resolution Representation Learning for Visual Recognition},
  author={Jingdong Wang and Ke Sun and Tianheng Cheng and Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2019},
  volume={43},
  pages={3349-3364}
}

@article{Dong2021,
author = {Dong, Shi and Wang, Ping and Abbas, Khushnood},
title = {A Survey on Deep Learning and Its Applications},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100379},
doi = {10.1016/j.cosrev.2021.100379},
journal = {Comput. Sci. Rev.},
month = {may},
numpages = {22},
keywords = {Deep belief networks, Stacked auto encoder, Convolutional neural network, Deep Boltzmann machine, Deep learning}
}


@article{Chai2021,
title = {Deep learning in computer vision: A critical review of emerging techniques and application scenarios},
journal = {Machine Learning with Applications},
volume = {6},
pages = {100134},
year = {2021},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100134},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021000670},
author = {Junyi Chai and Hao Zeng and Anming Li and Eric W.T. Ngai},
keywords = {Machine learning, Deep learning, Computer vision, Literature review},
abstract = {Deep learning has been overwhelmingly successful in computer vision (CV), natural language processing, and video/speech recognition. In this paper, our focus is on CV. We provide a critical review of recent achievements in terms of techniques and applications. We identify eight emerging techniques, investigate their origins and updates, and finally emphasize their applications in four key scenarios, including recognition, visual tracking, semantic segmentation, and image restoration. We recognize three development stages in the past decade and emphasize research trends for future works. The summarizations, knowledge accumulations, and creations could benefit researchers in the academia and participators in the CV industries.}
}

@article{GUO2020127,
title = {GAN-Based virtual-to-real image translation for urban scene semantic segmentation},
journal = {Neurocomputing},
volume = {394},
pages = {127-135},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.01.115},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219308847},
author = {Xi Guo and Zhicheng Wang and Qin Yang and Weifeng Lv and Xianglong Liu and Qiong Wu and Jian Huang},
keywords = {Domain adaptation, Virtual-to-real image translation, Generative adversarial networks, Semantic segmentation, Deep convolutional neural networks},
}

@inproceedings{vaswani2017attention,
  added-at = {2019-01-14T18:39:11.000+0100},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  biburl = {https://www.bibsonomy.org/bibtex/2a08c93d224dfcfb83550246c3d6a178f/stefan.ernst},
  booktitle = {Advances in Neural Information Processing Systems},
  description = {Aktuelleres Paper zur Verwendung von Attention für die Neural Machine Translation},
  interhash = {c9bf08cbcb15680c807e12a01dd8c929},
  intrahash = {a08c93d224dfcfb83550246c3d6a178f},
  keywords = {final thema:attention},
  pages = {5998--6008},
  timestamp = {2019-01-14T18:39:11.000+0100},
  title = {Attention is all you need},
  year = 2017
}


@InProceedings{Lin_2019_ICCV,
author = {Lin, Hubert and Upchurch, Paul and Bala, Kavita},
title = {Block Annotation: Better Image Annotation With Sub-Image Decomposition},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@inproceedings{clark-etal-2019-bert,
    title = "What Does {BERT} Look at? An Analysis of {BERT}{'}s Attention",
    author = "Clark, Kevin  and
      Khandelwal, Urvashi  and
      Levy, Omer  and
      Manning, Christopher D.",
    booktitle = "2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    year = "2019",
    url = "https://aclanthology.org/W19-4828",
    doi = "10.18653/v1/W19-4828",
    pages = "276--286",
}

@inproceedings{attentionisnot,
    title = "Attention is not not Explanation",
    author = "Wiegreffe, Sarah  and Pinter, Yuval",
    booktitle = "2019 Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
    url = "https://aclanthology.org/D19-1002",
    doi = "10.18653/v1/D19-1002",
    pages = "11--20",
    }
@mastersthesis{alcover2021exploring,
  title={On exploring the use of synthetic data for semantic segmentation in videos},
  author={Alcover Couso, Roberto},
  year={2021},
  school={Universidad Autónoma de Madrid}
}

@article{Nowruzi2019HowMR,
  title={How much real data do we actually need: Analyzing object detection performance using synthetic and real data},
  author={Farzan Erlik Nowruzi and Prince Kapoor and Dhanvin Kolhatkar and Fahed Al Hassanat and Robert Lagani{\`e}re and Julien Rebut},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.07061}
}

@INPROCEEDINGS{Biasetton2019,
  author={Biasetton, Matteo and Michieli, Umberto and Agresti, Gianluca and Zanuttigh, Pietro},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Unsupervised Domain Adaptation for Semantic Segmentation of Urban Scenes}, 
  year={2019},
  volume={},
  number={},
  pages={1211-1220},
  doi={10.1109/CVPRW.2019.00160}}


@inproceedings{Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}

@inproceedings{
hamilton2022unsupervised,
title={Unsupervised Semantic Segmentation by Distilling Feature Correspondences},
author={Mark Hamilton and Zhoutong Zhang and Bharath Hariharan and Noah Snavely and William T. Freeman},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=SaKO6z6Hl0c}
}

@INPROCEEDINGS{Sun2017,
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Revisiting Unreasonable Effectiveness of Data in Deep Learning Era}, 
  year={2017},
  volume={},
  number={},
  pages={843-852},
  doi={10.1109/ICCV.2017.97}}

@inproceedings{Dhariwal2021,
 author = {Dhariwal, Prafulla and Nichol, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {8780--8794},
 publisher = {Curran Associates, Inc.},
 title = {Diffusion Models Beat GANs on Image Synthesis},
 url = {https://proceedings.neurips.cc/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{Croitoru2022DiffusionMI,
  title={Diffusion Models in Vision: A Survey},
  author={Florinel-Alin Croitoru and Vlad Hondru and Radu Tudor Ionescu and Mubarak Shah},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.04747}
}

@article{DMSurveyArxivCao,
      title={A Survey on Generative Diffusion Model}, 
      author={Hanqun Cao and Cheng Tan and Zhangyang Gao and Guangyong Chen and Pheng-Ann Heng and Stan Z. Li},
      year={2022},
      journal = {ArXiv},
      doi={10.48550/ARXIV.2209.02646},
      url = {https://arxiv.org/abs/2209.02646},
      volume={abs/2209.02646}
}

@INPROCEEDINGS{Kirill2022,
  author={Sirotkin, Kirill and Carballeira, Pablo and Escudero-Viñolo, Marcos},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A study on the distribution of social biases in self-supervised learning visual models}, 
  year={2022},
  volume={},
  number={},
  pages={10432-10441},
  doi={10.1109/CVPR52688.2022.01019}}


@article{Promptist,
  doi = {10.48550/ARXIV.2212.09611},
  
  url = {https://arxiv.org/abs/2212.09611},
  
  author = {Hao, Yaru and Chi, Zewen and Dong, Li and Wei, Furu},
  
  keywords = {Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Optimizing Prompts for Text-to-Image Generation},
  
  journal = {ArXiv},
  volume={abs/2212.09611},
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{HardPromptsMadeEasy,
  doi = {10.48550/ARXIV.2302.03668},
  url = {https://arxiv.org/abs/2302.03668},
  author = {Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  volume = {abs/2302.03668},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery},
  journal = {ArXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{AttendAndExcite,
  doi = {10.48550/ARXIV.2301.13826},
  
  url = {https://arxiv.org/abs/2301.13826},
  
  author = {Chefer, Hila and Alaluf, Yuval and Vinker, Yael and Wolf, Lior and Cohen-Or, Daniel},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models},
  
  journal = {ArXiv},
  volume={abs/2301.13826},
  year = {2023},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{SALEEM2022165,
title = {Explaining deep neural networks: A survey on the global interpretation methods},
journal = {Neurocomputing},
volume = {513},
pages = {165-180},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.09.129},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222012218},
author = {Rabia Saleem and Bo Yuan and Fatih Kurugollu and Ashiq Anjum and Lu Liu},
keywords = {Artificial intelligence, Deep neural networks, Black box Models, Explainable artificial intelligence, Global interpretation},
abstract = {A substantial amount of research has been carried out in Explainable Artificial Intelligence (XAI) models, especially in those which explain the deep architectures of neural networks. A number of XAI approaches have been proposed to achieve trust in Artificial Intelligence (AI) models as well as provide explainability of specific decisions made within these models. Among these approaches, global interpretation methods have emerged as the prominent methods of explainability because they have the strength to explain every feature and the structure of the model. This survey attempts to provide a comprehensive review of global interpretation methods that completely explain the behaviour of the AI models. We present a taxonomy of the available global interpretations models and systematically highlight the critical features and algorithms that differentiate them from local as well as hybrid models of explainability. Through examples and case studies from the literature, we evaluate the strengths and weaknesses of the global interpretation models and assess challenges when these methods are put into practice. We conclude the paper by providing the future directions of research in how the existing challenges in global interpretation methods could be addressed and what values and opportunities could be realized by the resolution of these challenges.}
}

@article{Ghorbani_Abid_Zou_2019, title={Interpretation of Neural Networks Is Fragile}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4252}, DOI={10.1609/aaai.v33i01.33013681}, number={01}, journal={2019 AAAI Conference on Artificial Intelligence}, author={Ghorbani, Amirata and Abid, Abubakar and Zou, James}, year={2019}, month={Jul.}, pages={3681-3688} }

@article{Liu2022CausalRM,
  title={Causal Reasoning Meets Visual Representation Learning: A Prospective Study},
  author={Y. Liu and Yushen Wei and Hongyu Yan and Guanbin Li and Liang Lin},
  journal={Machine Intelligence Research},
  year={2022},
  volume={19},
  pages={485 - 511}
}

@InProceedings{conterfactual2019,
  title = 	 {Counterfactual Visual Explanations},
  author =       {Goyal, Yash and Wu, Ziyan and Ernst, Jan and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle = 	 {2019 International Conference on Machine Learning (ICML)},
  pages = 	 {2376--2384},
  year = 	 {2019},
  volume = 	 {97},
  pdf = 	 {http://proceedings.mlr.press/v97/goyal19a/goyal19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/goyal19a.html},
}


@INPROCEEDINGS {featureInversion,
author = {A. Mahendran and A. Vedaldi},
booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Understanding deep image representations by inverting them},
year = {2015},
volume = {},
issn = {1063-6919},
pages = {5188-5196},
abstract = {Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.},
keywords = {},
doi = {10.1109/CVPR.2015.7299155},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2015.7299155},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@article{Zhou2014ObjectDE,
  title={Object Detectors Emerge in Deep Scene CNNs},
  author={Bolei Zhou and Aditya Khosla and {\`A}gata Lapedriza and Aude Oliva and Antonio Torralba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6856}
}

@article{Fong2017InterpretableEO,
  title={Interpretable Explanations of Black Boxes by Meaningful Perturbation},
  author={Ruth C. Fong and Andrea Vedaldi},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={3449-3457}
}

@inproceedings{rombach2022high,
  added-at = {2022-09-05T11:03:26.000+0200},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  biburl = {https://www.bibsonomy.org/bibtex/28253f81df661643c915d38d2e317d17d/tobias.koopmann},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  interhash = {e54e035bdfef24c40a2133cbe99ac3bb},
  intrahash = {8253f81df661643c915d38d2e317d17d},
  keywords = {readinglist},
  pages = {10684--10695},
  timestamp = {2022-09-05T11:03:26.000+0200},
  title = {High-resolution image synthesis with latent diffusion models},
  year = 2022
}

@article{kazerouni2022diffusion,
  title={Diffusion Models for Medical Image Analysis: A Comprehensive Survey},
  author={Kazerouni, Amirhossein and Aghdam, Ehsan Khodapanah and Heidari, Moein and Azad, Reza and Fayyaz, Mohsen and Hacihaliloglu, Ilker and Merhof, Dorit},
  journal={ArXiv},
  volume={abs/2211.07804},
  year={2022}
}

@Article{jimaging8110310,
AUTHOR = {Man, Keith and Chahl, Javaan},
TITLE = {A Review of Synthetic Image Data and Its Use in Computer Vision},
JOURNAL = {Journal of Imaging},
VOLUME = {8},
YEAR = {2022},
NUMBER = {11},
ARTICLE-NUMBER = {310},
URL = {https://www.mdpi.com/2313-433X/8/11/310},
PubMedID = {36422059},
ISSN = {2313-433X},
ABSTRACT = {Development of computer vision algorithms using convolutional neural networks and deep learning has necessitated ever greater amounts of annotated and labelled data to produce high performance models. Large, public data sets have been instrumental in pushing forward computer vision by providing the data necessary for training. However, many computer vision applications cannot rely on general image data provided in the available public datasets to train models, instead requiring labelled image data that is not readily available in the public domain on a large scale. At the same time, acquiring such data from the real world can be difficult, costly to obtain, and manual labour intensive to label in large quantities. Because of this, synthetic image data has been pushed to the forefront as a potentially faster and cheaper alternative to collecting and annotating real data. This review provides general overview of types of synthetic image data, as categorised by synthesised output, common methods of synthesising different types of image data, existing applications and logical extensions, performance of synthetic image data in different applications and the associated difficulties in assessing data performance, and areas for further research.},
DOI = {10.3390/jimaging8110310}
}


@article{DaDiffusion,
  doi = {10.48550/ARXIV.2302.07944},
  url = {https://arxiv.org/abs/2302.07944},
  author = {Trabucco, Brandon and Doherty, Kyle and Gurinas, Max and Salakhutdinov, Ruslan},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Effective Data Augmentation With Diffusion Models},
  journal = {ArXiv},
  volume={abs/2302.07944},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{TabDDPM,
  doi = {10.48550/ARXIV.2209.15421},
  url = {https://arxiv.org/abs/2209.15421},
  author = {Kotelnikov, Akim and Baranchuk, Dmitry and Rubachev, Ivan and Babenko, Artem},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TabDDPM: Modelling Tabular Data with Diffusion Models},
  journal = {ArXiv},
  year = {2022},
  volume={abs/2209.15421},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@incollection{rumelhart:errorpropnonote,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  biburl = {https://www.bibsonomy.org/bibtex/27c3d39c519530239660d33e66493ade1/schaul},
  booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, {V}olume 1: {F}oundations},
  citeulike-article-id = {2378884},
  description = {idsia},
  interhash = {dd8485b30b80c7f35263bcb21ed81c1f},
  intrahash = {7c3d39c519530239660d33e66493ade1},
  keywords = {nn},
  pages = {318--362},
  priority = {2},
  publisher = {MIT Press},
  timestamp = {2008-02-26T12:02:43.000+0100},
  title = {Learning Internal Representations by Error Propagation},
  year = 1986
}

@article{DAAM,
  doi = {10.48550/ARXIV.2210.04885},
  url = {https://arxiv.org/abs/2210.04885},
  author = {Tang, Raphael and Liu, Linqing and Pandey, Akshat and Jiang, Zhiying and Yang, Gefei and Kumar, Karun and Stenetorp, Pontus and Lin, Jimmy and Ture, Ferhan},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {What the DAAM: Interpreting Stable Diffusion Using Cross Attention},
  journal = {ArXiv},
  volume={abs/2210.04885},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{shapley,
 author = {Lundberg, Scott M and Lee, Su-In},
 booktitle = {2017 Advances in Neural Information Processing Systems},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf},
 volume = {30},
 year = {2017},
 pages = {4768–4777},
 numpages = {10},
}

@INPROCEEDINGS{gradcam,
  author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}, 
  year={2017},
  volume={},
  number={},
  pages={618-626},
  doi={10.1109/ICCV.2017.74}}
  
@article{promptEngineering,
author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
title = {Learning to Prompt for Vision-Language Models},
year = {2022},
issue_date = {Sep 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {130},
number = {9},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-022-01653-1},
doi = {10.1007/s11263-022-01653-1},
journal = {Int. J. Comput. Vision},
month = {sep},
pages = {2337–2348},
numpages = {12}
}


@INPROCEEDINGS{extremalPerturbations,
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Understanding Deep Networks via Extremal Perturbations and Smooth Masks}, 
  year={2019},
  volume={},
  number={},
  pages={2950-2958},
  doi={10.1109/ICCV.2019.00304}}
  
@article{optimizationInput,
author = {Erhan, Dumitru and Bengio, Y. and Courville, Aaron and Vincent, Pascal},
year = {2009},
month = {01},
pages = {},
title = {Visualizing Higher-Layer Features of a Deep Network},
journal = {Technical Report, Univeristé de Montréal}
}

@inproceedings{Gerlings2020ReviewingTN,
  title={Reviewing the Need for Explainable Artificial Intelligence (xAI)},
  author={Julie Gerlings and Arisa Shollo and Ioanna D. Constantiou},
  booktitle={Hawaii International Conference on System Sciences},
  year={2020}
}

@article{Dalle2,
  title={Hierarchical Text-Conditional Image Generation with CLIP Latents},
  author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.06125}
}


@inproceedings{ballard:modular,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Ballard, Dana H.},
  biburl = {https://www.bibsonomy.org/bibtex/217eb5a7b6ab898f099b6675c7e7d2ea3/schaul},
  booktitle = {Sixth National Conference on Artificial Intelligence},
  citeulike-article-id = {2375728},
  description = {idsia},
  interhash = {c616c959bdfa632f6961529154757f25},
  intrahash = {17eb5a7b6ab898f099b6675c7e7d2ea3},
  keywords = {nn},
  pages = {279--284},
  priority = {2},
  timestamp = {2008-02-26T12:06:27.000+0100},
  title = {Modular Learning in Neural Networks},
  url = {http://www.mpi-sb.mpg.de/services/library/proceedings/contents/aaai87.html},
  year = 1987
}

@InProceedings{neurips/convolutionalautoencoders,
author="Guo, Xifeng and Liu, Xinwang and Zhu, En and Yin, Jianping",
title="Deep Clustering with Convolutional Autoencoders",
booktitle="Neural Information Processing",
year="2017",
pages="373--382",
isbn="978-3-319-70096-0"
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@ARTICLE{places,
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Places: A 10 Million Image Database for Scene Recognition}, 
  year={2018},
  volume={40},
  number={6},
  pages={1452-1464},
  doi={10.1109/TPAMI.2017.2723009}}

@INPROCEEDINGS{CAM,
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning Deep Features for Discriminative Localization}, 
  year={2016},
  volume={},
  number={},
  pages={2921-2929},
  doi={10.1109/CVPR.2016.319}}
  
@article{cocodataset,
  author    = {Tsung{-}Yi Lin and Michael Maire and Serge J. Belongie and Lubomir D. Bourdev and Ross B. Girshick and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{'{a} }r and C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{GeirhosRMBWB19,
  added-at = {2019-07-25T00:00:00.000+0200},
  author = {Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
  booktitle = {2019 International Conference on Learning Representations (ICLR)},
  keywords = {dblp},
  timestamp = {2019-07-26T11:39:47.000+0200},
  title = {ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2019.html#GeirhosRMBWB19},
  year = 2019
}

@INPROCEEDINGS{Fong2019,
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Understanding Deep Networks via Extremal Perturbations and Smooth Masks}, 
  year={2019},
  volume={},
  number={},
  pages={2950-2958},
  doi={10.1109/ICCV.2019.00304}}


@article{Simonyan2013DeepIC,
  title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
  author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
  journal={CoRR},
  year={2013},
  volume={abs/1312.6034}
}

@article{Rothe-IJCV-2018,
  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal = {International Journal of Computer Vision},
  volume={126},
  number={2-4},
  pages={144--157},
  year={2018},
  publisher={Springer}
}

@inproceedings{conf/icml/VincentLBM08,
  added-at = {2018-11-14T00:00:00.000+0100},
  author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  biburl = {https://www.bibsonomy.org/bibtex/2386a0cbca1fc421b487f1fe89856a48a/dblp},
  booktitle = {2008 International Conference on Machine Learning (ICML)},
  ee = {https://www.wikidata.org/entity/Q57257952},
  interhash = {f53f01391a871310794be6721ca56fc8},
  intrahash = {386a0cbca1fc421b487f1fe89856a48a},
  isbn = {978-1-60558-205-4},
  keywords = {dblp},
  pages = {1096-1103},
  timestamp = {2018-11-15T16:57:49.000+0100},
  title = {Extracting and composing robust features with denoising autoencoders.},
  url = {http://dblp.uni-trier.de/db/conf/icml/icml2008.html#VincentLBM08},
  volume = 307,
  year = 2008
}
@inproceedings{HoEtAl2020,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {6840--6851},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 volume = {33},
 year = {2020}
}



@inproceedings{zhang2016colorful,
  title={Colorful Image Colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={2016 European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{conf/icml/RifaiVMGB11,
  added-at = {2019-04-03T00:00:00.000+0200},
  author = {Rifai, Salah and Vincent, Pascal and Muller, Xavier and Glorot, Xavier and Bengio, Yoshua},
  biburl = {https://www.bibsonomy.org/bibtex/28f26a7044285547aa837507603c30b77/dblp},
  booktitle = {2011 International Conference on Machine Learning (ICML)},
  ee = {https://icml.cc/2011/papers/455_icmlpaper.pdf},
  interhash = {e19f80ada701efa67ab82010144c430e},
  intrahash = {8f26a7044285547aa837507603c30b77},
  keywords = {dblp},
  pages = {833-840},
  timestamp = {2019-04-04T11:48:16.000+0200},
  title = {Contractive Auto-Encoders: Explicit Invariance During Feature Extraction.},
  url = {http://dblp.uni-trier.de/db/conf/icml/icml2011.html#RifaiVMGB11},
  year = 2011
}

@INPROCEEDINGS{IEEE/Pathak2016,
  author={Pathak, Deepak and Krähenbühl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Context Encoders: Feature Learning by Inpainting}, 
  year={2016},
  volume={},
  number={},
  pages={2536-2544},
  doi={10.1109/CVPR.2016.278}}

@INPROCEEDINGS{ieee/zhang2017,
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction}, 
  year={2017},
  volume={},
  number={},
  pages={645-654},
  abstract={We propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task - predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve crosschannel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks.},
  keywords={},
  doi={10.1109/CVPR.2017.76},
  ISSN={1063-6919},
  month={July},}

@InProceedings{Shu_2018_ECCV,
author = {Shu, Zhixin and Sahasrabudhe, Mihir and Guler, Riza Alp and Samaras, Dimitris and Paragios, Nikos and Kokkinos, Iasonas},
title = {Deforming Autoencoders: Unsupervised Disentangling of Shape and Appearance},
booktitle = {2018 European Conference on Computer Vision (ECCV)},
year = {2018}
}

@article{liu2023audioldm,
      title={AudioLDM: Text-to-Audio Generation with Latent Diffusion Models}, 
      author={Haohe Liu and Zehua Chen and Yi Yuan and Xinhao Mei and Xubo Liu and Danilo Mandic and Wenwu Wang and Mark D. Plumbley},
      year={2023},
      volume={abs/2301.12503},
      journal={arXiv},
}

@inProceedings{Takagi2023HighresolutionIR,
  title={High-resolution image reconstruction with latent diffusion models from human brain activity},
  author={Yu Takagi and Shinji Nishimoto},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{ovtrack,
  author    = {Siyuan Li and
               Tobias Fischer and
               Lei Ke and
               Henghui Ding and
               Martin Danelljan and
               Fisher Yu},
  title     = {OVTrack: Open-Vocabulary Multiple Object Tracking},
      year={2023},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@article{xu2022odise,
  author    = {Xu, Jiarui and Liu, Sifei and Vahdat, Arash and Byeon, Wonmin and Wang, Xiaolong and De Mello, Shalini},
  title     = {{ODISE: Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models}},
  journal   = {ArXiv},
  volume={abs/2303.04803},
  year      = {2023},
}

@inproceedings{Kingma2014,
  added-at = {2020-10-15T14:36:56.000+0200},
  author = {Kingma, Diederik P. and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/242e5be6faa01cba2587f4907ac99dce8/annakrause},
  booktitle = {2014 International Conference on Learning Representations (ICLR)},
  eprint = {http://arxiv.org/abs/1312.6114v10},
  eprintclass = {stat.ML},
  eprinttype = {arXiv},
  file = {:http\://arxiv.org/pdf/1312.6114v10:PDF;:KingmaWelling_Auto-EncodingVariationalBayes.pdf:PDF},
  interhash = {a626a9d77a123c52405a08da983203cb},
  intrahash = {42e5be6faa01cba2587f4907ac99dce8},
  keywords = {cs.LG stat.ML vae},
  timestamp = {2021-02-01T17:13:18.000+0100},
  title = {{Auto-Encoding Variational Bayes}},
  year = 2014
}

@inproceedings{NIPS2017_7a98af17,
 author = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Neural Discrete Representation Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{NIPS2014_5ca3e9b1,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{radford2015unsupervised,
 author       = {Alec Radford and Luke Metz and Soumith Chintala},
  title        = {Unsupervised Representation Learning with Deep Convolutional Generative
                  Adversarial Networks},
  booktitle    = {2016 International Conference on Learning Representations (ICLR)},
  year         = {2016},
  url          = {http://arxiv.org/abs/1511.06434},
  timestamp    = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RadfordMC15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{journals/corr/abs-1711-10337,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lucic, Mario and Kurach, Karol and Michalski, Marcin and Gelly, Sylvain and Bousquet, Olivier},
  biburl = {https://www.bibsonomy.org/bibtex/2d5265aabda3547eb48218a66bdc15f47/dblp},
  ee = {http://arxiv.org/abs/1711.10337},
  interhash = {08ed1e03b0c226fc20b13d9caf8345a0},
  intrahash = {d5265aabda3547eb48218a66bdc15f47},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:31:48.000+0200},
  title = {Are GANs Created Equal? A Large-Scale Study.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1711.html#abs-1711-10337},
  volume = {abs/1711.10337},
  year = 2017
}

@inproceedings{NIPS2015_aa169b49,
 author = {Denton, Emily L and Chintala, Soumith and szlam, arthur and Fergus, Rob},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks},
 url = {https://proceedings.neurips.cc/paper/2015/file/aa169b49b583a2b5af89203c2b78c67c-Paper.pdf},
 volume = {28},
 year = {2015}
}

@inproceedings{NIPS2016_8a3363ab,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
 booktitle = {2016 Advances in Neural Information Processing Systems},
 pages = {},
 title = {Improved Techniques for Training GANs},
 url = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{conf/nips/ChenCDHSSA16,
  added-at = {2020-03-06T00:00:00.000+0100},
  author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  biburl = {https://www.bibsonomy.org/bibtex/2d837a1418dbe582963a9ea0e5460626b/dblp},
  booktitle = {2016 Neural Information Processing Systems (NIPS)},
  ee = {http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets},
  interhash = {f78500e0cdab0f0b259d0d1087c1588e},
  intrahash = {d837a1418dbe582963a9ea0e5460626b},
  keywords = {dblp},
  pages = {2172-2180},
  timestamp = {2020-03-07T11:53:22.000+0100},
  title = {InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.},
  url = {http://dblp.uni-trier.de/db/conf/nips/nips2016.html#ChenCDHSSA16},
  year = 2016
}


@InProceedings{pmlr-v48-reed16,
  title = 	 {Generative Adversarial Text to Image Synthesis},
  author = 	 {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1060--1069},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/reed16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/reed16.html},
  abstract = 	 {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories such as faces, album covers, room interiors and flowers. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.}
}


@InProceedings{Zhang2019,
  title = 	 {Self-Attention Generative Adversarial Networks},
  author =       {Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7354--7363},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/zhang19d/zhang19d.pdf},
  url = 	 {https://proceedings.mlr.press/v97/zhang19d.html},
  abstract = 	 {In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN performs better than prior work, boosting the best published Inception score from 36.8 to 52.52 and reducing Fréchet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.}
}

@article{Mordvintsev2015InceptionismGD,
  title={Inceptionism: Going Deeper into Neural Networks},
  author={A. Mordvintsev and Christopher Olah and Mike Tyka},
  year={2015},
  journal={Google Res. Blog}
}

@article{ackley:boltzmann,
  added-at = {2008-02-26T12:05:08.000+0100},
  annote = {Reprinted in \npcite{anderson:neurocomputing}},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  biburl = {https://www.bibsonomy.org/bibtex/2ac037874304d5e66687d47509d0c6916/schaul},
  citeulike-article-id = {2375554},
  description = {idsia},
  interhash = {e559274185c852d10cd56f62b54efdf7},
  intrahash = {ac037874304d5e66687d47509d0c6916},
  journal = {Cognitive Science},
  keywords = {nn},
  pages = {147--169},
  priority = {2},
  timestamp = {2008-02-26T12:06:46.000+0100},
  title = {A Learning Algorithm for {B}oltzmann Machines},
  volume = 9,
  year = 1985
}

@article{deb2023atman,
      title={AtMan: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation}, 
      author={Mayukh Deb and Björn Deiseroth and Samuel Weinbach and Patrick Schramowski and Kristian Kersting},
      year={2023},
      volume={abs/2301.08110},
      journal={ArXiv},
      primaryClass={cs.LG}
}

@inproceedings{
karras2018progressive,
title={Progressive Growing of {GAN}s for Improved Quality, Stability, and Variation},
author={Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
booktitle={2018 International Conference on Learning Representations (ICLR)},
year={2018},
url={https://openreview.net/forum?id=Hk99zCeAb},
}

@inproceedings{
brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}


@INPROCEEDINGS{Isola2017,
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Image-to-Image Translation with Conditional Adversarial Networks}, 
  year={2017},
  volume={},
  number={},
  pages={5967-5976},
  doi={10.1109/CVPR.2017.632}}

  @article{Wang2018,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  biburl = {https://www.bibsonomy.org/bibtex/27a383cd6af11f8ed1160a1660068c0a7/dblp},
  ee = {http://arxiv.org/abs/1711.11585},
  interhash = {46d42caa8e804f80c1ab7b0c4b67bfce},
  intrahash = {7a383cd6af11f8ed1160a1660068c0a7},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T15:21:45.000+0200},
  title = {High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1711.html#abs-1711-11585},
  volume = {abs/1711.11585},
  year = 2017
}


@InProceedings{dalle1,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {2021 International Conference on Machine Learning (ICML)},
  pages = 	 {8821--8831},
  year = 	 {2021},
  volume = 	 {139},
  pdf = 	 {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/ramesh21a.html},
}


@INPROCEEDINGS{Park2019,
  author={Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Semantic Image Synthesis With Spatially-Adaptive Normalization}, 
  year={2019},
  volume={},
  number={},
  pages={2332-2341},
  doi={10.1109/CVPR.2019.00244}}

@inproceedings{wang2018-video,
author = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
title = {Video-to-Video Synthesis},
year = {2018},
booktitle = {2018 Neural Information Processing Systems (NIPS)},
pages = {1152–1164},
numpages = {13},
}

@article{Asperti2021,
author = {Asperti, Andrea and Evangelista, Davide and Piccolomini, E.Loli},
year = {2021},
month = {07},
pages = {},
title = {A Survey on Variational Autoencoders from a Green AI Perspective},
volume = {2},
journal = {SN Computer Science},
doi = {10.1007/s42979-021-00702-9}
}

@article{Asperti2022,
author = {Asperti, Andrea and Tonelli, Valerio},
year = {2022},
month = {10},
pages = {},
title = {Comparing the latent space of generative models},
volume = {35},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-022-07890-2}
}
@misc{borsos2022audiolm,
      title={AudioLM: a Language Modeling Approach to Audio Generation}, 
      author={Zalán Borsos and Raphaël Marinier and Damien Vincent and Eugene Kharitonov and Olivier Pietquin and Matt Sharifi and Olivier Teboul and David Grangier and Marco Tagliasacchi and Neil Zeghidour},
      year={2022},
      eprint={2209.03143},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@article{ho2022imagen,
      title={Imagen Video: High Definition Video Generation with Diffusion Models}, 
      author={Jonathan Ho and William Chan and Chitwan Saharia and Jay Whang and Ruiqi Gao and Alexey Gritsenko and Diederik P. Kingma and Ben Poole and Mohammad Norouzi and David J. Fleet and Tim Salimans},
      year={2022},
      volume={abs/2210.02303},
      journal={ArXiv},
      primaryClass={cs.CV}
}

@inproceedings{shen2020interpreting,
  author={Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Interpreting the Latent Space of GANs for Semantic Face Editing}, 
  year={2020},
  volume={},
  number={},
  pages={9240-9249},
  doi={10.1109/CVPR42600.2020.00926}}

@article{Pham2022,
author = {Pham, Chi-Hieu and Ladjal, Saïd and Newson, Alasdair},
year = {2022},
month = {06},
pages = {1-17},
title = {PCA-AE: Principal Component Analysis Autoencoder for Organising the Latent Space of Generative Networks},
volume = {64},
journal = {Journal of Mathematical Imaging and Vision},
doi = {10.1007/s10851-022-01077-z}
}

@inproceedings{Radford2021LearningTV,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and A. Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={2021 International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{QuanshiZHANG,
author = {Quan-shi ZHANG, Song-chun ZHU},
title = {Visual interpretability for deep learning: a survey},
publisher = {Front. Inform. Technol. Electron. Eng},
year = {2018},
journal = {Frontiers of Information Technology \& Electronic Engineering},
volume = {19},
number = {1},
eid = {27},
numpages = {12},
pages = {27},
keywords = {Artificial intelligence;Deep learning;Interpretable model},
url = {https://journal.hep.com.cn/ckcest/fitee/EN/abstract/article_22283.shtml},
doi = {10.1631/FITEE.1700808}
}    

